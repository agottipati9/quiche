{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bddc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea54860",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380304cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metrics_from_log(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parses a QUICHE log file, extracting all METRICS_LOG JSON blobs.\n",
    "    \n",
    "    Args:\n",
    "        filepath: The Path object to the log file.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing all metrics, or an empty DataFrame\n",
    "        if no metrics are found.\n",
    "    \"\"\"\n",
    "    # Regex to find the JSON blob in lines containing METRICS_LOG\n",
    "    # It handles both \"Client: METRICS_LOG {json}\" and \"Server: METRICS_LOG {json}\"\n",
    "    metrics_regex = re.compile(r'METRICS_LOG ({.*})')\n",
    "    \n",
    "    metrics_data = []\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                match = metrics_regex.search(line)\n",
    "                if match:\n",
    "                    try:\n",
    "                        # Extract and parse the JSON blob\n",
    "                        data = json.loads(match.group(1))\n",
    "                        metrics_data.append(data)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Warning: Skipping malformed JSON in {filepath.name}\", file=sys.stderr)\n",
    "                        \n",
    "    except IOError as e:\n",
    "        print(f\"Error reading file {filepath}: {e}\", file=sys.stderr)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if not metrics_data:\n",
    "        # This is very common for server logs that don't emit metrics, so no warning.\n",
    "        pass\n",
    "        \n",
    "    return pd.DataFrame(metrics_data)\n",
    "\n",
    "\n",
    "def plot_summary_boxplot(\n",
    "    data_by_algo: dict,\n",
    "    y_label: str,\n",
    "    output_filename: str,\n",
    "    label_map: dict,\n",
    "    scale_factor: float = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates and saves a box plot using academic-style settings.\n",
    "\n",
    "    Args:\n",
    "        data_by_algo: Aggregated data (dict of {algo_key: [values]}).\n",
    "        y_label: The label for the Y-axis.\n",
    "        output_filename: The filename to save the plot as.\n",
    "        label_map: Dictionary to map algorithm keys to display names.\n",
    "        scale_factor: A factor to scale the metric by.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Academic style settings from your reference\n",
    "    academic_style_settings = {\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'DejaVu Serif'],\n",
    "        'font.size': 18,\n",
    "        'axes.titlesize': 18,\n",
    "        'axes.labelsize': 26,\n",
    "        'xtick.labelsize': 24,\n",
    "        'ytick.labelsize': 24,\n",
    "        'legend.fontsize': 18,\n",
    "        'pdf.fonttype': 42,  # Use Type 1 fonts for PDF output\n",
    "        'ps.fonttype': 42    # Use Type 1 fonts for PostScript output\n",
    "    }\n",
    "\n",
    "    # Use rc_context to apply settings temporarily\n",
    "    try:\n",
    "        with plt.rc_context(academic_style_settings):\n",
    "            fig, ax = plt.subplots(figsize=(15, 7), dpi=300)\n",
    "            \n",
    "            plot_data = []\n",
    "            plot_labels = []\n",
    "\n",
    "            # Sort items for consistent plot order\n",
    "            sorted_items = sorted(data_by_algo.items(), key=lambda item: label_map.get(item[0], item[0]))\n",
    "\n",
    "            for algo, values in sorted_items:\n",
    "                if values:\n",
    "                    # Apply scaling to the aggregated values\n",
    "                    scaled_values = np.array(values) * scale_factor\n",
    "                    plot_data.append(scaled_values)\n",
    "                    # Use the \"pretty\" name from the map\n",
    "                    plot_labels.append(label_map.get(algo, algo))\n",
    "                    print(f\"Boxplot data for {algo} ({label_map.get(algo, algo)}): {len(scaled_values)} samples.\")\n",
    "                else:\n",
    "                    print(f\"Warning: No data found for {algo}, skipping.\", file=sys.stderr)\n",
    "\n",
    "\n",
    "            if not plot_data:\n",
    "                print(f\"Error: No data to plot for {output_filename}\", file=sys.stderr)\n",
    "                plt.close(fig)\n",
    "                return\n",
    "\n",
    "            # --- Plotting logic from your reference ---\n",
    "            box_plot = ax.boxplot(plot_data, \n",
    "                                  patch_artist=True,  # Fill boxes with color\n",
    "                                  labels=plot_labels,\n",
    "                                  showfliers=False, \n",
    "                                  medianprops=dict(linewidth=2), \n",
    "                                  showmeans=False, \n",
    "                                  meanline=False)\n",
    "\n",
    "            # Define grayscale/blue edge colors\n",
    "            edge_shades = [\"#1b4965\", \"#2c7da0\", \"#5fa8d3\", \"#90befe\"] \n",
    "\n",
    "            for i, box in enumerate(box_plot['boxes']):\n",
    "                shade = edge_shades[i % len(edge_shades)]\n",
    "                box.set(facecolor=\"none\", edgecolor=shade, linewidth=4)\n",
    "\n",
    "            for i, (whiskerL, whiskerR) in enumerate(zip(box_plot['whiskers'][0::2],\n",
    "                                                        box_plot['whiskers'][1::2])):\n",
    "                shade = edge_shades[i % len(edge_shades)]\n",
    "                whiskerL.set(color=shade, linewidth=4)\n",
    "                whiskerR.set(color=shade, linewidth=4)\n",
    "\n",
    "            for i, (capL, capR) in enumerate(zip(box_plot['caps'][0::2],\n",
    "                                                box_plot['caps'][1::2])):\n",
    "                shade = edge_shades[i % len(edge_shades)]\n",
    "                capL.set(color=shade, linewidth=4)\n",
    "                capR.set(color=shade, linewidth=4)\n",
    "\n",
    "            for i, median in enumerate(box_plot['medians']):\n",
    "                median.set(color=edge_shades[i % len(edge_shades)], linewidth=2.5)\n",
    "\n",
    "            ax.set_xticks(np.arange(1, len(plot_labels) + 1))\n",
    "            ax.set_xticklabels(plot_labels, ha='center')\n",
    "            \n",
    "            ax.set_ylabel(y_label)\n",
    "\n",
    "            # Clean plot\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.grid(axis='y', linestyle='--', alpha=0.7) # Add grid\n",
    "\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            try:\n",
    "                plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
    "                print(f\"Successfully generated plot: {output_filename}\")\n",
    "            except IOError as e:\n",
    "                print(f\"Error saving plot {output_filename}: {e}\", file=sys.stderr)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying academic plot style (may need Times New Roman font): {e}\", file=sys.stderr)\n",
    "        # Fallback to default style if it fails\n",
    "        plt.close() # Close potentially broken plot\n",
    "\n",
    "def plot_summary_barplot(\n",
    "    data_by_algo: dict,\n",
    "    y_label: str,\n",
    "    output_filename: str,\n",
    "    label_map: dict,\n",
    "    scale_factor: float = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates and saves a bar plot of the median values,\n",
    "    using academic-style settings.\n",
    "\n",
    "    Args:\n",
    "        data_by_algo: Aggregated data (dict of {algo: [values]}).\n",
    "        y_label: The label for the Y-axis.\n",
    "        output_filename: The filename to save the plot as.\n",
    "        label_map: Dictionary to map algorithm keys to display names.\n",
    "        scale_factor: A factor to scale the metric by.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Academic style settings\n",
    "    academic_style_settings = {\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times New Roman', 'DejaVu Serif'],\n",
    "        'font.size': 18,\n",
    "        'axes.titlesize': 18,\n",
    "        'axes.labelsize': 26,\n",
    "        'xtick.labelsize': 24,\n",
    "        'ytick.labelsize': 24,\n",
    "        'legend.fontsize': 18,\n",
    "        'pdf.fonttype': 42,  # Use Type 1 fonts for PDF output\n",
    "        'ps.fonttype': 42    # Use Type 1 fonts for PostScript output\n",
    "    }\n",
    "\n",
    "    # Use rc_context to apply settings temporarily\n",
    "    try:\n",
    "        with plt.rc_context(academic_style_settings):\n",
    "            fig, ax = plt.subplots(figsize=(15, 7), dpi=300)\n",
    "            \n",
    "            plot_data_medians = []\n",
    "            plot_labels = []\n",
    "\n",
    "            # Sort items for consistent plot order\n",
    "            sorted_items = sorted(data_by_algo.items(), key=lambda item: label_map.get(item[0], item[0]))\n",
    "\n",
    "            for algo, values in sorted_items:\n",
    "                if values:\n",
    "                    # Calculate the median and apply scaling\n",
    "                    scaled_median = np.median(np.array(values)) * scale_factor\n",
    "                    plot_data_medians.append(scaled_median)\n",
    "                    # Use the \"pretty\" name from the map\n",
    "                    plot_labels.append(label_map.get(algo, algo))\n",
    "                    print(f\"Bar data for {algo}: {len(values)} samples, median={scaled_median:.2f}\")\n",
    "                else:\n",
    "                    print(f\"Warning: No data for {algo}, skipping.\", file=sys.stderr)\n",
    "\n",
    "\n",
    "            if not plot_data_medians:\n",
    "                print(f\"Error: No data to plot for {output_filename}\", file=sys.stderr)\n",
    "                plt.close(fig)\n",
    "                return\n",
    "\n",
    "            # --- Plotting logic REVISED for bar chart ---\n",
    "            \n",
    "            # Create x-axis positions\n",
    "            x_positions = np.arange(len(plot_labels))\n",
    "            \n",
    "            # Plot the bars\n",
    "            bars = ax.bar(x_positions, \n",
    "                          plot_data_medians,  # Use medians as bar heights\n",
    "                          align='center',\n",
    "                          width=0.7)          # Bar width\n",
    "\n",
    "            # Define grayscale/blue edge colors\n",
    "            edge_shades = [\"#1b4965\", \"#2c7da0\", \"#5fa8d3\", \"#90befe\"] \n",
    "\n",
    "            # Apply styling to each bar\n",
    "            for i, bar in enumerate(bars):\n",
    "                shade = edge_shades[i % len(edge_shades)]\n",
    "                bar.set_edgecolor(shade)\n",
    "                bar.set_facecolor(shade)\n",
    "                bar.set_linewidth(4)  # Match old boxplot line width\n",
    "\n",
    "            # Set x-axis ticks and labels\n",
    "            ax.set_xticks(x_positions)\n",
    "            ax.set_xticklabels(plot_labels, ha='center')\n",
    "            \n",
    "            # --- End of revised plotting logic ---\n",
    "\n",
    "            ax.set_ylabel(y_label)\n",
    "\n",
    "            # Clean plot\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.grid(axis='y', linestyle='--', alpha=0.7) # Add grid\n",
    "            \n",
    "            # set ylims\n",
    "            plt.ylim(0.5, 1.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            try:\n",
    "                plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
    "                print(f\"Successfully generated plot: {output_filename}\")\n",
    "            except IOError as e:\n",
    "                print(f\"Error saving plot {output_filename}: {e}\", file=sys.stderr)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying academic plot style (may need Times New Roman font): {e}\", file=sys.stderr)\n",
    "        # Fallback to default style if it fails\n",
    "        plt.close() # Close potentially broken plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn style for better-looking plots\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except IOError:\n",
    "    print(\"Seaborn style not available, using default.\", file=sys.stderr)\n",
    "\n",
    "log_dir = Path(\".\") \n",
    "\n",
    "# 1. Define Mappings\n",
    "# Map the directory name to the internal algorithm key (used in filenames)\n",
    "dir_to_key = {\n",
    "    'CUBIC': 'QBIC',\n",
    "    'BBRv1': 'BBRR',\n",
    "    'BBRv3': 'B2ON',\n",
    "    'LLM-BBR': 'LLMX'\n",
    "    # Add other methods here if needed, e.g., 'Prague': 'PRGC'\n",
    "}\n",
    "\n",
    "# Map the internal algorithm key to the \"pretty name\" for plot labels\n",
    "key_to_label = {\n",
    "    'QBIC': 'CUBIC',\n",
    "    'BBRR': 'BBRv1',\n",
    "    'B2ON': 'BBRv3',\n",
    "    'LLMX': 'LLM-BBR' # Using 'Ours' as in your original 'label_to_name'\n",
    "    # 'PRGC': 'Prague'\n",
    "}\n",
    "\n",
    "# We'll calculate the mean of the metric after the first 30s\n",
    "STABLE_START_TIME_MS = 0 # 30000 \n",
    "\n",
    "# 2. Initialize Data Aggregators\n",
    "goodput_data_by_algo = defaultdict(list)\n",
    "srtt_data_by_algo = defaultdict(list)\n",
    "queuing_delay_data_by_algo = defaultdict(list) # NEW\n",
    "\n",
    "cwnd_data_by_algo = defaultdict(list)\n",
    "retransmit_data_by_algo = defaultdict(list) # NEW\n",
    "bw_est_data_by_algo = defaultdict(list) # NEW\n",
    "pacing_rate_data_by_algo = defaultdict(list) # NEW\n",
    "\n",
    "\n",
    "print(\"\\n--- Aggregating Data from Sub-directories ---\")\n",
    "\n",
    "# 3. Iterate Over Directories and Aggregate Data\n",
    "for dir_name, algo_key in dir_to_key.items():\n",
    "    sub_dir = log_dir / dir_name\n",
    "    \n",
    "    if not sub_dir.is_dir():\n",
    "        print(f\"Warning: Directory not found, skipping: {sub_dir}\", file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    # Find all relevant log files using the algorithm key\n",
    "    client_files = sorted(sub_dir.glob(f\"performance_log_{algo_key}_client_*.txt\"))\n",
    "    server_files = sorted(sub_dir.glob(f\"performance_log_{algo_key}_server_*.txt\"))\n",
    "    \n",
    "    print(f\"Processing '{dir_name}' (Key: {algo_key}): Found {len(client_files)} client logs, {len(server_files)} server logs.\")\n",
    "\n",
    "    if not client_files and not server_files:\n",
    "        print(f\"Warning: No log files found in {dir_name} for key {algo_key}\", file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    # 3.1. Process Client Logs (Goodput, SRTT, Queuing Delay)\n",
    "    for c_file in client_files:\n",
    "        df = parse_metrics_from_log(c_file)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Get stable data\n",
    "        df_stable = df[df['time_ms'] > STABLE_START_TIME_MS]\n",
    "        df_to_use = df_stable if not df_stable.empty else df\n",
    "\n",
    "        # Extract Goodput\n",
    "        if \"goodput_bps\" in df_to_use.columns:\n",
    "            goodput_data_by_algo[algo_key].extend(df_to_use[\"goodput_bps\"].to_list())\n",
    "        \n",
    "        # Extract SRTT\n",
    "        if \"srtt_ms\" in df_to_use.columns:\n",
    "            srtt_data_by_algo[algo_key].extend(df_to_use[\"srtt_ms\"].to_list())\n",
    "\n",
    "        # Extract Queuing Delay (from latest_rtt_us)\n",
    "        if \"latest_rtt_us\" in df_to_use.columns:\n",
    "            queuing_delay_data_by_algo[algo_key].extend(df_to_use[\"latest_rtt_us\"].to_list())\n",
    "\n",
    "    # 3.2. Process Server Logs (CWND, Retransmits, BW Est, Pacing Rate)\n",
    "    for s_file in server_files:\n",
    "        df = parse_metrics_from_log(s_file)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Get stable data (for gauges like CWND, BW Est, Pacing)\n",
    "        df_stable = df[df['time_ms'] > STABLE_START_TIME_MS]\n",
    "        df_to_use = df_stable if not df_stable.empty else df\n",
    "\n",
    "        # Extract CWND (gauge)\n",
    "        if \"cwnd_bytes\" in df_to_use.columns:\n",
    "            cwnd_data_by_algo[algo_key].extend(df_to_use[\"cwnd_bytes\"].to_list())\n",
    "        \n",
    "        # Extract BW Estimate (gauge)\n",
    "        if \"est_bw_bps\" in df_to_use.columns:\n",
    "            bw_est_data_by_algo[algo_key].extend(df_to_use[\"est_bw_bps\"].to_list())\n",
    "        \n",
    "        # Extract Pacing Rate (gauge)\n",
    "        if \"pacing_rate_bps\" in df_to_use.columns:\n",
    "            pacing_rate_data_by_algo[algo_key].extend(df_to_use[\"pacing_rate_bps\"].to_list())\n",
    "\n",
    "        # Extract *final* retransmit value (it's a counter)\n",
    "        # We use 'df' (full dataframe) to get the last recorded value.\n",
    "        if \"bytes_retrans\" in df.columns and not df.empty:\n",
    "            final_retrans_val = df[\"bytes_retrans\"].iloc[-1]\n",
    "            retransmit_data_by_algo[algo_key].append(final_retrans_val)\n",
    "\n",
    "print(\"\\n--- Data Aggregation Complete ---\")\n",
    "\n",
    "# Check if any data was aggregated at all\n",
    "all_data_aggregrators = [\n",
    "    goodput_data_by_algo, srtt_data_by_algo, queuing_delay_data_by_algo,\n",
    "    cwnd_data_by_algo, retransmit_data_by_algo, bw_est_data_by_algo,\n",
    "    pacing_rate_data_by_algo\n",
    "]\n",
    "if all(not d for d in all_data_aggregrators):\n",
    "     print(\"Error: No data was successfully aggregated from any directory.\", file=sys.stderr)\n",
    "     print(f\"Looked for directories: {list(dir_to_key.keys())}\", file=sys.stderr)\n",
    "     sys.exit(1)\n",
    "\n",
    "\n",
    "# 4. Generate Plots\n",
    "print(\"\\n--- Generating Summary Box Plots ---\")\n",
    "\n",
    "# 4.1 Goodput Box Plot (Client)\n",
    "print(\"Plotting Goodput...\")\n",
    "if goodput_data_by_algo:\n",
    "    plot_summary_boxplot(\n",
    "        data_by_algo=goodput_data_by_algo,\n",
    "        y_label=\"Goodput (Mbps)\",\n",
    "        output_filename=\"client_goodput_boxplot.png\",\n",
    "        label_map=key_to_label,\n",
    "        scale_factor=1 / 1_000_000 # Convert bps to Mbps\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping Goodput plot (no data).\")\n",
    "\n",
    "# 4.2 SRTT Box Plot (Client)\n",
    "print(\"Plotting SRTT...\")\n",
    "if srtt_data_by_algo:\n",
    "    plot_summary_boxplot(\n",
    "        data_by_algo=srtt_data_by_algo,\n",
    "        y_label=\"SRTT (ms)\",\n",
    "        output_filename=\"client_srtt_boxplot.png\",\n",
    "        label_map=key_to_label,\n",
    "        scale_factor=1.0 # Already in ms\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping SRTT plot (no data).\")\n",
    "\n",
    "# 4.3 Round Trip Delay Box Plot (Client)\n",
    "print(\"Plotting Round Trip Delay...\")\n",
    "if queuing_delay_data_by_algo:\n",
    "    plot_summary_boxplot(\n",
    "        data_by_algo=queuing_delay_data_by_algo,\n",
    "        y_label=\"RTT (ms)\",\n",
    "        output_filename=\"client_queuing_delay_boxplot.png\",\n",
    "        label_map=key_to_label,\n",
    "        scale_factor=1 # NOTE already in ms despite us log\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping Queuing Delay plot (no data).\")\n",
    "\n",
    "# 4.4 CWND Box Plot (Server)\n",
    "print(\"Plotting CWND...\")\n",
    "if cwnd_data_by_algo:\n",
    "    plot_summary_boxplot(\n",
    "        data_by_algo=cwnd_data_by_algo,\n",
    "        y_label=\"CWND (KB)\",\n",
    "        output_filename=\"server_cwnd_boxplot.png\",\n",
    "        label_map=key_to_label,\n",
    "        scale_factor=1 / 1024 # Convert bytes to KB\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping CWND plot (no data).\")\n",
    "\n",
    "# 4.5 Retransmits Box Plot (Server)\n",
    "print(\"Plotting Retransmits...\")\n",
    "if retransmit_data_by_algo:\n",
    "    plot_summary_boxplot(\n",
    "        data_by_algo=retransmit_data_by_algo,\n",
    "        y_label=\"Total Retransmitted (KB)\",\n",
    "        output_filename=\"server_retransmits_boxplot.png\",\n",
    "        label_map=key_to_label,\n",
    "        scale_factor=1 / 1024 # Convert bytes to KB\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping Retransmits plot (no data).\")\n",
    "\n",
    "# 4.6 Bandwidth Estimate Box Plot (Server)\n",
    "print(\"Plotting Bandwidth Estimate...\")\n",
    "if bw_est_data_by_algo:\n",
    "    plot_summary_boxplot(\n",
    "        data_by_algo=bw_est_data_by_algo,\n",
    "        y_label=\"Est. Bandwidth (Mbps)\",\n",
    "        output_filename=\"server_bw_est_boxplot.png\",\n",
    "        label_map=key_to_label,\n",
    "        scale_factor=1 / 1_000_000 # Convert bps to Mbps\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping Bandwidth Estimate plot (no data).\")\n",
    "\n",
    "# 4.7 Pacing Rate Box Plot (Server)\n",
    "print(\"Plotting Pacing Rate...\")\n",
    "if pacing_rate_data_by_algo:\n",
    "    plot_summary_boxplot(\n",
    "        data_by_algo=pacing_rate_data_by_algo,\n",
    "        y_label=\"Pacing Rate (Mbps)\",\n",
    "        output_filename=\"server_pacing_rate_boxplot.png\",\n",
    "        label_map=key_to_label,\n",
    "        scale_factor=1 / 1_000_000 # Convert bps to Mbps\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping Pacing Rate plot (no data).\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Plotting complete. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
